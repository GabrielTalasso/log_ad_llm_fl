{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/log_ad_llm_fl/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from utils import initialize_model, load_dataset, split_data, train_client, aggregate_models, set_adapters, save_global_model, get_adapters\n",
    "import warnings\n",
    "import torch\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "import json\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "import copy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "SIM_NAME = 'returning_model_loading'\n",
    "NUM_ROUNDS = 20\n",
    "NUM_CLIENTS = 20\n",
    "CLIENT_FRAC = 0.1\n",
    "MODEL_NAME = 'HuggingFaceTB/SmolLM-360M'\n",
    "path = '../.dataset/hdfs/tokenized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:27<00:00, 3687.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "global_model, tokenizer = initialize_model(MODEL_NAME, lora_rank=8, sim_name=SIM_NAME)\n",
    "rs = random.SystemRandom()\n",
    "tokenized_datasets = load_dataset(path, nrows=100000)\n",
    "clients_datasets, clients_datasets_eval = split_data(tokenized_datasets, NUM_CLIENTS)\n",
    "\n",
    "#remove \"text\" columns from all datasets\n",
    "for i in range(NUM_CLIENTS):\n",
    "    clients_datasets[i] = clients_datasets[i].remove_columns(\"text\")\n",
    "    clients_datasets_eval[i] = clients_datasets_eval[i].remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: Clients Selected [4, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: Client 4 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: Client 11 trained\n"
     ]
    }
   ],
   "source": [
    "#Select Clients\n",
    "clients = rs.sample(list(range(NUM_CLIENTS)), int(NUM_CLIENTS*CLIENT_FRAC))\n",
    "\n",
    "print(f\"Round {round}: Clients Selected {clients}\")\n",
    "\n",
    "# Train clients\n",
    "clients_models = []\n",
    "for client in clients:\n",
    "    client_model = train_client(int(client), clients_datasets[client], global_model, round, SIM_NAME, tokenizer, max_steps=1)\n",
    "    clients_models.append(client_model)\n",
    "    print(f\"Round {round}: Client {client} trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0014, -0.0128, -0.0179,  ..., -0.0038,  0.0056, -0.0038],\n",
      "        [ 0.0014, -0.0056,  0.0065,  ..., -0.0125, -0.0088, -0.0075],\n",
      "        [-0.0038, -0.0028, -0.0052,  ...,  0.0071,  0.0039,  0.0123],\n",
      "        ...,\n",
      "        [-0.0015,  0.0204, -0.0107,  ..., -0.0037,  0.0040,  0.0073],\n",
      "        [-0.0014,  0.0205, -0.0099,  ..., -0.0029,  0.0051,  0.0101],\n",
      "        [-0.0459, -0.0410, -0.0034,  ...,  0.0087, -0.0378, -0.0464]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0014, -0.0128, -0.0179,  ..., -0.0038,  0.0056, -0.0038],\n",
      "        [ 0.0014, -0.0056,  0.0065,  ..., -0.0125, -0.0088, -0.0075],\n",
      "        [-0.0038, -0.0028, -0.0052,  ...,  0.0071,  0.0039,  0.0123],\n",
      "        ...,\n",
      "        [-0.0015,  0.0204, -0.0107,  ..., -0.0037,  0.0040,  0.0073],\n",
      "        [-0.0014,  0.0205, -0.0099,  ..., -0.0029,  0.0051,  0.0101],\n",
      "        [-0.0459, -0.0410, -0.0034,  ...,  0.0087, -0.0378, -0.0464]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0014, -0.0128, -0.0179,  ..., -0.0038,  0.0056, -0.0038],\n",
      "        [ 0.0014, -0.0056,  0.0065,  ..., -0.0125, -0.0088, -0.0075],\n",
      "        [-0.0038, -0.0028, -0.0052,  ...,  0.0071,  0.0039,  0.0123],\n",
      "        ...,\n",
      "        [-0.0015,  0.0204, -0.0107,  ..., -0.0037,  0.0040,  0.0073],\n",
      "        [-0.0014,  0.0205, -0.0099,  ..., -0.0029,  0.0051,  0.0101],\n",
      "        [-0.0459, -0.0410, -0.0034,  ...,  0.0087, -0.0378, -0.0464]])\n"
     ]
    }
   ],
   "source": [
    "layer = 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight'\n",
    "print(clients_models[0].state_dict()[layer])\n",
    "print(clients_models[1].state_dict()[layer])\n",
    "print(global_model.state_dict()[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0008, -0.0011,  0.0007,  0.0015,  0.0014,  0.0015, -0.0015,  0.0012],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(clients_models[0]base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0003,  0.0005,  0.0010,  0.0013,  0.0012,  0.0016, -0.0014,  0.0003],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(clients_models[1])[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0008,  0.0003,  0.0011,  0.0014,  0.0011,  0.0016, -0.0014,  0.0010])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(global_model)[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate model\n",
    "aggregated_adapters = aggregate_models(clients_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0003, -0.0003,  0.0008,  0.0014,  0.0013,  0.0016, -0.0014,  0.0008],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_adapters[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_adapters(global_model, aggregated_adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_global_model(global_model, round, SIM_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "batch_size=32\n",
    "max_steps=1\n",
    "client_id = 0\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('HuggingFaceTB/SmolLM-360M')\n",
    "model = PeftModel.from_pretrained(model, f'fl-results/{SIM_NAME}/round_{round-1}/global_model', is_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0008,  0.0003,  0.0011,  0.0014,  0.0011,  0.0016, -0.0014,  0.0010])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(model)[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fl-results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    max_steps=max_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    save_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=max_steps+1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, client, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.train_losses = {}\n",
    "        self.validation_losses = {}\n",
    "        self.client = client\n",
    "\n",
    "    def log(self, logs):\n",
    "        # Save client losses\n",
    "        super().log(logs)\n",
    "        if \"loss\" in logs:\n",
    "            self.train_losses[client] = float(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.validation_losses[client] = float(logs[\"eval_loss\"])\n",
    "\n",
    "trainer = CustomTrainer(client=client,\n",
    "                        model=model,\n",
    "                        args=training_args,\n",
    "                        train_dataset=clients_datasets[client_id],\n",
    "                        eval_dataset=clients_datasets_eval[client_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(trainer.model)[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=1.6342928409576416, metrics={'train_runtime': 2.2872, 'train_samples_per_second': 13.991, 'train_steps_per_second': 0.437, 'total_flos': 31010429337600.0, 'train_loss': 1.6342928409576416, 'epoch': 0.1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2045e-05,  6.9064e-06, -2.7410e-05,  2.9566e-05, -1.2492e-05,\n",
       "        -2.4802e-05,  3.0794e-05,  2.1151e-05], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(trainer.model)[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2045e-05,  6.9064e-06, -2.7410e-05,  2.9566e-05, -1.2492e-05,\n",
       "        -2.4802e-05,  3.0794e-05,  2.1151e-05], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adapters(model)[\"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "output_dir = f\"./fl-results/{SIM_NAME}/round_{round}/client_{client}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "# Save losses\n",
    "with open(f\"{output_dir}/training_losses.json\", \"w\") as f:\n",
    "    json.dump(trainer.train_losses, f)\n",
    "\n",
    "with open(f\"{output_dir}/validation_losses.json\", \"w\") as f:\n",
    "    json.dump(trainer.validation_losses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
